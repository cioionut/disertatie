\chapter{Concluzii}

Vorbind dintr-o perspectivă academică, rezultatele obținute reușesc să convingă de adevărata putere a acestei arhitecturi.
Datorită rețelelor recurente se reușește captarea contextului, fapt ce duce la o putere mare de generalizare. Capacitatea modelului de a prezice crește atunci când in joc intervine și atenția, acest strat care ajută estimatorul să se concentreze pe anumite cuvinte atunci când decide asupra unei etichete.

Din perspectiva comercializării unei astfel de soluții există puține impedimente, dar totuși notabile și anume: în faza de antrenare este nevoie de un număr mare de exemple etichetate. Un alt factor care stă în calea scalării numărului de clienți este nevoia unui expert în domeniu care să concentreze în mulțimea de antrenare intenții și exemple relevante. Construirea unei astfel de mulțimi de antrenare necesită și implicarea dezvoltatorului (sau a unei persoanei care cunoaște cum funcționează tehnologia), astfel încât să se asigure că exemplele construite de expertul în domeniu, au o oarecare consistență, spre exemplu: dacă s-a dat propoziția: "vreau să imi resetez parola din aplicația Saturn" etichetat cu entitatea: app: Saturn, să existe și contra exemple în care să se specifice și celalalt sens al cuvântului "Saturn", astfel modulul de NLU să poată identifica cu succes atunci când este vorba de aplicație sau despre planetă.

Legat de componenta care ține contextul întregii conversații, este foarte ușor de urmărit întregul fir al discuției, datorită modelului bazat pe umplerea de sloturi (entități necesare în cadrul unei sarcini).

Modelele actuale cer un număr mare de date de antrenare, implementarea acestora în domenii specifice se lovește de lipsa informațiilor etichetate. Aceste neajunsuri fac ca atenția noastră să se îndrepte spre abordări ce privesc mai degrabă noi perspective legate de reprezentarea înțelesului.